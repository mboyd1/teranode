// Package pruner provides the Pruner Service which handles periodic pruning of unmined transaction
// parents and delete-at-height (DAH) records in the UTXO store.
//
// Trigger mechanism (event-driven):
// The pruning trigger mode is controlled by pruner_block_trigger setting:
//   - "OnBlockPersisted" (default): Pruning triggers on BlockPersisted notifications from block persister.
//     If block persister is not running, automatically falls back to Block notifications.
//   - "OnBlockMined": Pruning triggers on Block notifications after block has mined_set=true,
//     regardless of block persister status.
//
// Pruner operations only execute when safe to do so (i.e., when block assembly is in "running"
// state and not performing reorgs or resets).
package pruner

import (
	"context"
	"encoding/binary"
	"net/http"
	"strconv"
	"sync"
	"sync/atomic"
	"time"

	"github.com/bsv-blockchain/go-bt/v2/chainhash"
	"github.com/bsv-blockchain/teranode/errors"
	"github.com/bsv-blockchain/teranode/model"
	"github.com/bsv-blockchain/teranode/services/blockassembly"
	"github.com/bsv-blockchain/teranode/services/blockchain"
	"github.com/bsv-blockchain/teranode/services/pruner/pruner_api"
	"github.com/bsv-blockchain/teranode/settings"
	"github.com/bsv-blockchain/teranode/stores/blob"
	"github.com/bsv-blockchain/teranode/stores/blob/storetypes"
	"github.com/bsv-blockchain/teranode/stores/utxo"
	"github.com/bsv-blockchain/teranode/stores/utxo/pruner"
	"github.com/bsv-blockchain/teranode/ulogger"
	"github.com/bsv-blockchain/teranode/util"
	"github.com/bsv-blockchain/teranode/util/health"
	"github.com/ordishs/gocore"
	"google.golang.org/grpc"
)

// PruneRequest represents a pruning request with height and optional block hash.
// BlockHash is populated for Block notifications (needed for mined_set wait)
// and nil for BlockPersisted notifications (already mined by definition).
type PruneRequest struct {
	Height    uint32
	BlockHash *chainhash.Hash // nil for BlockPersisted
}

// BlobDeletionObserver is an optional callback interface for testing.
// It allows tests to be notified when blob deletion processing completes.
type BlobDeletionObserver interface {
	OnBlobDeletionComplete(height uint32, successCount, failCount int64)
}

// Server implements the Pruner service which handles periodic pruner operations
// for the UTXO store. It uses event-driven triggers: BlockPersisted notifications (primary)
// and Block notifications with mined_set wait (fallback when persister not running or forced via setting).
type Server struct {
	pruner_api.UnsafePrunerAPIServer

	// Dependencies (injected via constructor)
	ctx                 context.Context
	logger              ulogger.Logger
	settings            *settings.Settings
	utxoStore           utxo.Store
	blockchainClient    blockchain.ClientI
	blockAssemblyClient blockassembly.ClientI

	// Internal state
	prunerService       pruner.Service
	lastProcessedHeight atomic.Uint32
	lastPersistedHeight atomic.Uint32
	prunerCh            chan *PruneRequest
	stats               *gocore.Stat

	// Blob deletion
	blobStores           map[storetypes.BlobStoreType]blob.Store
	blobDeletionCh       chan *PruneRequest
	blobDeletionObserver BlobDeletionObserver
}

// New creates a new Pruner server instance with the provided dependencies.
// This function initializes the server but does not start any background processes.
// Call Init() and then Start() to begin operation.
func New(
	ctx context.Context,
	logger ulogger.Logger,
	tSettings *settings.Settings,
	utxoStore utxo.Store,
	blockchainClient blockchain.ClientI,
	blockAssemblyClient blockassembly.ClientI,
) *Server {
	return &Server{
		ctx:                 ctx,
		logger:              logger,
		settings:            tSettings,
		utxoStore:           utxoStore,
		blockchainClient:    blockchainClient,
		blockAssemblyClient: blockAssemblyClient,
		blobStores:          make(map[storetypes.BlobStoreType]blob.Store),
		blobDeletionCh:      make(chan *PruneRequest, 1),
		stats:               gocore.NewStat("pruner"),
	}
}

// Init initializes the pruner service. This is called before Start() and is responsible
// for setting up the pruner service provider from the UTXO store and subscribing to
// block persisted notifications for coordination with the block persister service.
func (s *Server) Init(ctx context.Context) error {
	s.ctx = ctx

	// Initialize metrics
	initPrometheusMetrics()

	// Initialize pruner service from UTXO store
	prunerProvider, ok := s.utxoStore.(pruner.PrunerServiceProvider)
	if !ok {
		return errors.NewServiceError("UTXO store does not provide pruner service")
	}

	var err error
	s.prunerService, err = prunerProvider.GetPrunerService()
	if err != nil {
		return errors.NewServiceError("failed to get pruner service", err)
	}
	if s.prunerService == nil {
		return errors.NewServiceError("pruner service not available from UTXO store")
	}

	// Validate block trigger mode
	blockTrigger := s.settings.Pruner.BlockTrigger
	if blockTrigger != settings.PrunerBlockTriggerOnBlockPersisted && blockTrigger != settings.PrunerBlockTriggerOnBlockMined {
		return errors.NewConfigurationError("pruner_block_trigger must be either '%s' or '%s' (got '%s')",
			settings.PrunerBlockTriggerOnBlockPersisted, settings.PrunerBlockTriggerOnBlockMined, blockTrigger)
	}

	// Blob deletion is now managed by blockchain service - no local DB needed

	// Subscribe to blockchain notifications for event-driven pruning:
	// - BlockPersisted: Triggers pruning when block persister completes (primary)
	// - Block: Waits for mined_set=true and triggers if persister not running (fallback)
	// Also tracks persisted height for coordination with store-level pruner safety checks
	subscriptionCh, err := s.blockchainClient.Subscribe(ctx, "Pruner")
	if err != nil {
		return errors.NewServiceError("failed to subscribe to blockchain notifications", err)
	}

	// Start a goroutine to handle blockchain notifications
	go func() {
		for notification := range subscriptionCh {
			if notification == nil {
				continue
			}

			switch notification.Type {
			case model.NotificationType_BlockPersisted:
				// Skip BlockPersisted notifications if using OnBlockMined trigger mode
				if s.settings.Pruner.BlockTrigger == settings.PrunerBlockTriggerOnBlockMined {
					s.logger.Debugf("Ignoring BlockPersisted notification (pruner_block_trigger=%s)", s.settings.Pruner.BlockTrigger)
					continue
				}

				// Track persisted height for coordination with block persister
				if notification.Metadata != nil && notification.Metadata.Metadata != nil {
					if heightStr, ok := notification.Metadata.Metadata["height"]; ok {
						if height, err := strconv.ParseUint(heightStr, 10, 32); err == nil {
							height32 := uint32(height)
							oldHeight := s.lastPersistedHeight.Swap(height32)

							// Log at INFO level when Block Persister first becomes active (transition from 0)
							if oldHeight == 0 && height32 > 0 {
								s.logger.Infof("[pruner] block persister is now active (persisted height: %d)", height32)
							} else {
								s.logger.Debugf("[pruner] updated persisted height to %d", height32)
							}

							// Queue pruning request
							if height32 > s.lastProcessedHeight.Load() {
								// Extract block hash from notification
								var blockHash *chainhash.Hash
								if notification.Hash != nil {
									var err error
									blockHash, err = chainhash.NewHash(notification.Hash)
									if err != nil {
										s.logger.Warnf("Failed to parse block hash from BlockPersisted notification: %v", err)
										blockHash = nil
									}
								}

								req := &PruneRequest{
									Height:    height32,
									BlockHash: blockHash, // For logging - BlockPersisted implies already mined
								}

								// Try to queue pruning (Phase 1 & 2, will trigger blob pruning)
								select {
								case s.prunerCh <- req:
									hashStr := "<unknown>"
									if blockHash != nil {
										hashStr = blockHash.String()
									}
									s.logger.Infof("[pruner][%s:%d] queued from BlockPersisted notification", hashStr, height32)
								default:
									hashStr := "<unknown>"
									if blockHash != nil {
										hashStr = blockHash.String()
									}
									s.logger.Warnf("[pruner][%s:%d] pruner channel full, skipping (already running)", hashStr, height32)
								}
							}
						}
					}
				}

			case model.NotificationType_Block:
				// Skip if using OnBlockPersisted trigger mode
				if s.settings.Pruner.BlockTrigger == settings.PrunerBlockTriggerOnBlockPersisted {
					s.logger.Debugf("Block notification received but pruner configured for BlockPersisted trigger")
					continue
				}

				// Extract block hash (required for mined_set wait in processor)
				if notification.Hash == nil {
					s.logger.Debugf("Block notification missing hash, skipping")
					continue
				}

				blockHash, err := chainhash.NewHash(notification.Hash)
				if err != nil {
					s.logger.Debugf("Failed to parse block hash from notification: %v", err)
					continue
				}

				// Get height from blockchain client using the block hash
				// This is the authoritative source and avoids race conditions with Block Assembly state updates
				header, meta, err := s.blockchainClient.GetBlockHeader(ctx, blockHash)
				if err != nil {
					s.logger.Debugf("Failed to get block header for Block notification hash %s: %v", blockHash, err)
					continue
				}
				if header == nil || meta == nil {
					s.logger.Debugf("Block notification for hash %s has no header/meta", blockHash)
					continue
				}
				height := meta.Height

				// Queue pruning request immediately - processor will wait for mined_set if block assembly is running
				if height > s.lastProcessedHeight.Load() {
					req := &PruneRequest{
						Height:    height,
						BlockHash: blockHash, // Needed for mined_set wait
					}

					select {
					case s.prunerCh <- req:
						s.logger.Infof("[pruner][%s:%d] queued from Block notification",
							blockHash.String(), height)
					default:
						s.logger.Warnf("[pruner][%s:%d] pruner channel full, skipping (already running)",
							blockHash.String(), height)
					}
				}
			}
		}
	}()

	// Read initial persisted height from blockchain state
	if state, err := s.blockchainClient.GetState(ctx, "BlockPersisterHeight"); err == nil && len(state) >= 4 {
		height := binary.LittleEndian.Uint32(state)
		s.lastPersistedHeight.Store(height)
		s.logger.Infof("Loaded initial block persister height: %d", height)
	}

	return nil
}

// Start begins the pruner service operation. It starts the pruner processor goroutine,
// then starts the gRPC server. Pruning is triggered by BlockPersisted and Block notifications.
// This function blocks until the server shuts down or encounters an error.
func (s *Server) Start(ctx context.Context, readyCh chan<- struct{}) error {
	var closeOnce sync.Once
	defer closeOnce.Do(func() { close(readyCh) })

	// Wait for blockchain FSM to be ready
	err := s.blockchainClient.WaitUntilFSMTransitionFromIdleState(ctx)
	if err != nil {
		return err
	}

	// Initialize pruner channel (buffer of 1 to prevent blocking while ensuring only one pruner)
	s.prunerCh = make(chan *PruneRequest, 1)

	// Start the pruner service (Aerospike or SQL)
	if s.prunerService != nil {
		s.prunerService.Start(ctx)
	}

	// Start pruner processor goroutine
	go s.prunerProcessor(ctx)

	// Trigger initial pruning if there's work to do
	// This ensures the pruner starts working immediately on startup
	// rather than waiting for the next block notification
	go func() {
		var currentHeight uint32
		var blockHash *chainhash.Hash

		// Determine height based on trigger mode
		blockTrigger := s.settings.Pruner.BlockTrigger

		if blockTrigger == settings.PrunerBlockTriggerOnBlockPersisted {
			// OnBlockPersisted mode: Use persisted height from block persister
			currentHeight = s.lastPersistedHeight.Load()
			// blockHash remains nil - BlockPersisted implies already mined

		} else if blockTrigger == settings.PrunerBlockTriggerOnBlockMined {
			// OnBlockMined mode: Get current blockchain height
			if tipHeader, tipMeta, err := s.blockchainClient.GetBestBlockHeader(ctx); err == nil && tipHeader != nil && tipMeta != nil {
				currentHeight = tipMeta.Height
				blockHash = tipHeader.Hash() // Need hash for mined_set wait
			} else {
				s.logger.Warnf("[pruner] failed to get best block header for initial pruning: %v", err)
				return
			}
		}

		// Queue initial pruning if we have a valid height
		if currentHeight > 0 && currentHeight > s.lastProcessedHeight.Load() {
			req := &PruneRequest{
				Height:    currentHeight,
				BlockHash: blockHash,
			}

			hashStr := "<startup>"
			if blockHash != nil {
				hashStr = blockHash.String()
			}

			select {
			case s.prunerCh <- req:
				s.logger.Infof("[pruner][%s:%d] triggered initial pruning on startup (mode: %s)", hashStr, currentHeight, blockTrigger)
			case <-time.After(5 * time.Second):
				s.logger.Warnf("[pruner] failed to queue initial pruning request (timeout)")
			case <-ctx.Done():
				return
			}
		} else if currentHeight == 0 {
			s.logger.Infof("[pruner] no initial pruning needed (current height: 0)")
		} else {
			s.logger.Debugf("[pruner] no initial pruning needed (current height: %d, last processed: %d)", currentHeight, s.lastProcessedHeight.Load())
		}
	}()

	// Start blob deletion worker
	go s.blobDeletionWorker()

	// Start blob deletion metrics updater
	go s.updateBlobDeletionMetrics()

	// Note: Polling worker not needed - pruning is triggered by:
	// 1. BlockPersisted notifications (when block persister is running)
	// 2. Block notifications with mined_set wait (when persister not running)

	// Start gRPC server (BLOCKING - must be last)
	if err := util.StartGRPCServer(ctx, s.logger, s.settings, "pruner",
		s.settings.Pruner.GRPCListenAddress,
		func(server *grpc.Server) {
			pruner_api.RegisterPrunerAPIServer(server, s)
			closeOnce.Do(func() { close(readyCh) })
		}, nil); err != nil {
		return err
	}

	return nil
}

// Stop gracefully shuts down the pruner service. Context cancellation will stop
// the polling worker and pruner processor goroutines.
func (s *Server) Stop(ctx context.Context) error {
	// Stop the pruner service if it has a Stop method
	if s.prunerService != nil {
		// Check if the pruner service implements Stop
		// Aerospike has Stop, SQL doesn't
		type stopper interface {
			Stop(ctx context.Context) error
		}
		if stoppable, ok := s.prunerService.(stopper); ok {
			if err := stoppable.Stop(ctx); err != nil {
				s.logger.Errorf("Error stopping pruner service: %v", err)
			}
		}
	}

	// Context cancellation will stop goroutines
	s.logger.Infof("Pruner service stopped")
	return nil
}

// Health implements the health check for the pruner service. When checkLiveness is true,
// it only checks if the service process is running. When false, it checks all dependencies
// including gRPC server, block assembly client, blockchain client, and UTXO store.
func (s *Server) Health(ctx context.Context, checkLiveness bool) (int, string, error) {
	if checkLiveness {
		// LIVENESS: Is the service process running?
		return http.StatusOK, "OK", nil
	}

	// READINESS: Can the service handle requests?
	checks := make([]health.Check, 0, 5)

	// Check gRPC server is listening
	if s.settings.Pruner.GRPCListenAddress != "" {
		checks = append(checks, health.Check{
			Name: "gRPC Server",
			Check: health.CheckGRPCServerWithSettings(s.settings.Pruner.GRPCListenAddress, s.settings, func(ctx context.Context, conn *grpc.ClientConn) error {
				// Simple connection check - if we can create a client, server is up
				return nil
			}),
		})
	}

	// Check block assembly client
	if s.blockAssemblyClient != nil {
		checks = append(checks, health.Check{
			Name:  "BlockAssemblyClient",
			Check: s.blockAssemblyClient.Health,
		})
	}

	// Check blockchain client
	if s.blockchainClient != nil {
		checks = append(checks, health.Check{
			Name:  "BlockchainClient",
			Check: s.blockchainClient.Health,
		})
		checks = append(checks, health.Check{
			Name:  "FSM",
			Check: blockchain.CheckFSM(s.blockchainClient),
		})
	}

	// Check UTXO store
	if s.utxoStore != nil {
		checks = append(checks, health.Check{
			Name:  "UTXOStore",
			Check: s.utxoStore.Health,
		})
	}

	return health.CheckAll(ctx, checkLiveness, checks)
}

// HealthGRPC implements the gRPC health check endpoint.
func (s *Server) HealthGRPC(ctx context.Context, _ *pruner_api.EmptyMessage) (*pruner_api.HealthResponse, error) {
	// Add context value to prevent circular dependency when checking gRPC server
	ctx = context.WithValue(ctx, "skip-grpc-self-check", true)

	status, details, err := s.Health(ctx, false)

	return &pruner_api.HealthResponse{
		Ok:      status == http.StatusOK,
		Details: details,
	}, errors.WrapGRPC(err)
}

// SetBlobDeletionObserver sets an optional observer for blob deletion completion events.
// This is primarily used for testing to synchronize test execution with deletion processing.
func (s *Server) SetBlobDeletionObserver(observer BlobDeletionObserver) {
	s.blobDeletionObserver = observer
}
